{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9bcc578",
   "metadata": {},
   "source": [
    "## Omer contour from rembg needs testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b41510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install rembg\n",
    "# %pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05015c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51adfee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Tests for the plugin system\n",
    "\"\"\"\n",
    "import pytest\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import importlib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "\n",
    "\n",
    "# Import plugin modules\n",
    "from pyptv import ptv\n",
    "from pyptv.ptv import py_start_proc_c, py_trackcorr_init, py_sequence_loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92476fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside main of pyptv_batch, exp_path is /media/user/ExtremePro/omer/exp2 \n",
      "\n",
      "double checking that its inside /media/user/ExtremePro/omer/exp2 \n",
      "\n",
      "first frame is 1\n",
      "last frame is 101\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "exp_path = Path('/media/user/ExtremePro/omer/exp2')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "try:\n",
    "    exp_path = Path(exp_path).resolve()\n",
    "    print(f\"Inside main of pyptv_batch, exp_path is {exp_path} \\n\")\n",
    "    os.chdir(exp_path)\n",
    "    \n",
    "    print(f\"double checking that its inside {Path.cwd()} \\n\")\n",
    "except Exception:\n",
    "    raise ValueError(f\"Wrong experimental directory {exp_path}\")\n",
    "\n",
    "# RON - make a res dir if it not found\n",
    "\n",
    "res_path = exp_path / \"res\"\n",
    "\n",
    "if not res_path.is_dir():\n",
    "    print(\" 'res' folder not found. creating one\")\n",
    "    res_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# read the number of cameras\n",
    "with open(\"parameters/ptv.par\", \"r\") as f:\n",
    "    n_cams = int(f.readline())\n",
    "\n",
    "cpar, spar, vpar, track_par, tpar, cals, epar = py_start_proc_c(n_cams=n_cams)\n",
    "\n",
    "\n",
    "first_frame = spar.get_first()\n",
    "last_frame = spar.get_last()\n",
    "\n",
    "\n",
    "## For debugging\n",
    "if last_frame - first_frame > 500:\n",
    "    last_frame = first_frame + 500\n",
    "\n",
    "print(f\"first frame is {first_frame}\")\n",
    "print(f\"last frame is {last_frame}\")\n",
    "\n",
    "# spar.set_first(first_frame)\n",
    "spar.set_last(last_frame)\n",
    "\n",
    "\n",
    "exp = {\n",
    "'cpar':cpar,\n",
    "'spar':spar,\n",
    "'vpar':vpar,\n",
    "'track_par':track_par,\n",
    "'tpar':tpar,\n",
    "'cals':cals,\n",
    "'epar':epar,\n",
    "'n_cams':n_cams,\n",
    "    }\n",
    "\n",
    "\n",
    "# use dataclass to convert dictionary keys to attributes\n",
    "exp = AttrDict(exp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa8f14",
   "metadata": {},
   "source": [
    "### Next steps: or load plugin from the file or for debugging load the code into this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5000ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    py_sequence_loop(exp)\n",
    "from pyptv.ptv import run_plugin\n",
    "\n",
    "# plugin_dir = Path('/home/user/Documents/repos/pyptv/pyptv') / 'plugins'\n",
    "# sys.path.append(str(plugin_dir))\n",
    "\n",
    "# print(f\"Plugin directory contents: {list(plugin_dir.glob('*.py'))}\")\n",
    "\n",
    "# plugin_file =  plugin_dir / 'ext_sequence_rembg_contour.py'\n",
    "\n",
    "\n",
    "# if not plugin_file.exists():\n",
    "#     raise FileNotFoundError(f\"Plugin file not found at {plugin_file}\")\n",
    "\n",
    "\n",
    "# plugin = importlib.import_module('ext_sequence_rembg_contour')\n",
    "# sequence = plugin.Sequence(exp=exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91aab37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %load /home/user/Documents/repos/pyptv/pyptv/plugins/ext_sequence_rembg_contour.py\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from imageio.v3 import imread, imwrite\n",
    "from pathlib import Path\n",
    "\n",
    "from skimage import img_as_ubyte\n",
    "from skimage import filters, measure, morphology\n",
    "from skimage.color import rgb2gray, label2rgb, rgba2rgb\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.morphology import binary_erosion, binary_dilation, disk\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "from optv.correspondences import correspondences, MatchedCoords\n",
    "from optv.tracker import default_naming\n",
    "from optv.orientation import point_positions\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rembg import remove, new_session\n",
    "session = new_session('u2net')\n",
    "\n",
    "def save_mask_areas(areas_data: list, output_file: Path) -> None:\n",
    "    \"\"\"Save mask areas to CSV file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    areas_data : list\n",
    "        List of dictionaries containing camera number, frame number, and area\n",
    "    output_file : Path\n",
    "        Path to output CSV file\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(areas_data)\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "def mask_image(imname: Path, display: bool = False) -> tuple[np.ndarray, float]:\n",
    "    \"\"\"Mask the image using rembg and keep the entire mask.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    imname : Path\n",
    "        Path to the image file\n",
    "    display : bool\n",
    "        Whether to display debug plots\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    tuple[np.ndarray, float]\n",
    "        Masked image and the area of the mask below row 600 in pixels\n",
    "    \"\"\"\n",
    "    input_data = imread(imname)\n",
    "    mask = remove(input_data, session=session, only_mask=True)\n",
    "    \n",
    "    # Set ROI threshold\n",
    "    y_threshold = 600\n",
    "    \n",
    "    # Create ROI mask below threshold\n",
    "    roi_mask = np.zeros_like(mask, dtype=bool)\n",
    "    roi_mask[y_threshold:, :] = True\n",
    "    \n",
    "    # Calculate area in ROI\n",
    "    mask_in_roi = np.where(roi_mask, mask, False)\n",
    "    area = np.sum(mask_in_roi)\n",
    "    \n",
    "    if display:\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Original image\n",
    "        ax1.imshow(input_data)\n",
    "        ax1.axhline(y=y_threshold, color='r', linestyle='--')\n",
    "        ax1.set_title('Original image')\n",
    "        \n",
    "        # Full mask\n",
    "        ax2.imshow(mask)\n",
    "        ax2.axhline(y=y_threshold, color='r', linestyle='--')\n",
    "        ax2.set_title('Full mask')\n",
    "        \n",
    "        # Masked image\n",
    "        ax3.imshow(np.where(mask, input_data, 0))\n",
    "        ax3.axhline(y=y_threshold, color='r', linestyle='--')\n",
    "        ax3.set_title('Masked image')\n",
    "        \n",
    "        # ROI masked image\n",
    "        ax4.imshow(np.where(mask_in_roi, input_data, 0))\n",
    "        ax4.set_title(f'ROI mask (area: {area} pixels)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # Apply the mask to the input image\n",
    "    masked_image = np.where(mask, input_data, 0)\n",
    "    return masked_image, area\n",
    "\n",
    "class Sequence:\n",
    "    \"\"\"Sequence class defines external tracking addon for pyptv\n",
    "    User needs to implement the following functions:\n",
    "            do_sequence(self)\n",
    "\n",
    "    Connection to C ptv module is given via self.ptv and provided by pyptv software\n",
    "    Connection to active parameters is given via self.exp1 and provided by pyptv software.\n",
    "\n",
    "    User responsibility is to read necessary files, make the calculations and write the files back.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ptv=None, exp=None):\n",
    "        self.ptv = ptv\n",
    "        self.exp = exp\n",
    "        self.areas_data = []  # Store areas data during processing\n",
    "\n",
    "    def do_sequence(self):\n",
    "        \"\"\" Copy of the sequence loop with one change we call everything as \n",
    "        self.ptv instead of ptv. \n",
    "        \n",
    "        \"\"\"\n",
    "        # Sequence parameters    \n",
    "\n",
    "        n_cams, cpar, spar, vpar, tpar, cals = (\n",
    "            self.exp.n_cams,\n",
    "            self.exp.cpar,\n",
    "            self.exp.spar,\n",
    "            self.exp.vpar,\n",
    "            self.exp.tpar,\n",
    "            self.exp.cals,\n",
    "        )\n",
    "\n",
    "        # # Sequence parameters\n",
    "        # spar = SequenceParams(num_cams=n_cams)\n",
    "        # spar.read_sequence_par(b\"parameters/sequence.par\", n_cams)\n",
    "\n",
    "\n",
    "        # sequence loop for all frames\n",
    "        first_frame = spar.get_first()\n",
    "        last_frame = spar.get_last()\n",
    "        print(f\" From {first_frame = } to {last_frame = }\")\n",
    "        \n",
    "        for frame in range(first_frame, last_frame + 1):\n",
    "            # print(f\"processing {frame = }\")\n",
    "\n",
    "            detections = []\n",
    "            corrected = []\n",
    "            for i_cam in range(n_cams):\n",
    "                base_image_name = spar.get_img_base_name(i_cam)\n",
    "                imname = Path(base_image_name % frame) # works with jumps from 1 to 10 \n",
    "                masked_image, area = mask_image(imname, display=False)\n",
    "\n",
    "                # Store area data\n",
    "                self.areas_data.append({\n",
    "                    'camera': i_cam,\n",
    "                    'frame': frame,\n",
    "                    'area': area\n",
    "                })                \n",
    "\n",
    "                # img = imread(imname)\n",
    "                # if img.ndim > 2:\n",
    "                #     img = rgb2gray(img)\n",
    "                    \n",
    "                # if img.dtype != np.uint8:\n",
    "                #     img = img_as_ubyte(img)\n",
    "\n",
    "                        \n",
    "                \n",
    "                high_pass = self.ptv.simple_highpass(masked_image, cpar)\n",
    "                targs = self.ptv.target_recognition(high_pass, tpar, i_cam, cpar)\n",
    "\n",
    "                targs.sort_y()\n",
    "                detections.append(targs)\n",
    "                masked_coords = MatchedCoords(targs, cpar, cals[i_cam])\n",
    "                pos, _ = masked_coords.as_arrays()\n",
    "                corrected.append(masked_coords)\n",
    "\n",
    "            #        if any([len(det) == 0 for det in detections]):\n",
    "            #            return False\n",
    "\n",
    "            # Corresp. + positions.\n",
    "            sorted_pos, sorted_corresp, _ = correspondences(\n",
    "                detections, corrected, cals, vpar, cpar)\n",
    "\n",
    "            # Save targets only after they've been modified:\n",
    "            # this is a workaround of the proper way to construct _targets name\n",
    "            for i_cam in range(n_cams):\n",
    "                base_name = spar.get_img_base_name(i_cam)\n",
    "                # base_name = replace_format_specifiers(base_name) # %d to %04d\n",
    "                self.ptv.write_targets(detections[i_cam], base_name, frame)\n",
    "\n",
    "            print(\"Frame \" + str(frame) + \" had \" +\n",
    "                repr([s.shape[1] for s in sorted_pos]) + \" correspondences.\")\n",
    "\n",
    "            # Distinction between quad/trip irrelevant here.\n",
    "            sorted_pos = np.concatenate(sorted_pos, axis=1)\n",
    "            sorted_corresp = np.concatenate(sorted_corresp, axis=1)\n",
    "\n",
    "            flat = np.array([\n",
    "                corrected[i].get_by_pnrs(sorted_corresp[i])\n",
    "                for i in range(len(cals))\n",
    "            ])\n",
    "            pos, _ = point_positions(flat.transpose(1, 0, 2), cpar, cals, vpar)\n",
    "\n",
    "            # if len(cals) == 1: # single camera case\n",
    "            #     sorted_corresp = np.tile(sorted_corresp,(4,1))\n",
    "            #     sorted_corresp[1:,:] = -1\n",
    "\n",
    "            if len(cals) < 4:\n",
    "                print_corresp = -1 * np.ones((4, sorted_corresp.shape[1]))\n",
    "                print_corresp[:len(cals), :] = sorted_corresp\n",
    "            else:\n",
    "                print_corresp = sorted_corresp\n",
    "\n",
    "            # Save rt_is\n",
    "            rt_is_filename = default_naming[\"corres\"].decode()\n",
    "            rt_is_filename = rt_is_filename + f'.{frame}'\n",
    "            with open(rt_is_filename, \"w\", encoding=\"utf8\") as rt_is:\n",
    "                rt_is.write(str(pos.shape[0]) + \"\\n\")\n",
    "                for pix, pt in enumerate(pos):\n",
    "                    pt_args = (pix + 1, ) + tuple(pt) + tuple(print_corresp[:, pix])\n",
    "                    rt_is.write(\"%4d %9.3f %9.3f %9.3f %4d %4d %4d %4d\\n\" % pt_args)\n",
    "\n",
    "            \n",
    "       \n",
    "        # After processing all frames, save the areas data\n",
    "        output_file = Path('res/mask_areas.csv')\n",
    "        save_mask_areas(self.areas_data, output_file)\n",
    "        print(f\"Mask areas saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1964e3a",
   "metadata": {},
   "source": [
    "### Here's the importan bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb129d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " From first_frame = 1 to last_frame = 101\n",
      "Frame 1 had [89, 313, 164] correspondences.\n",
      "Frame 2 had [87, 335, 158] correspondences.\n",
      "Frame 3 had [88, 345, 152] correspondences.\n",
      "Frame 4 had [85, 330, 160] correspondences.\n",
      "Frame 5 had [76, 343, 152] correspondences.\n",
      "Frame 6 had [79, 339, 157] correspondences.\n",
      "Frame 7 had [87, 340, 143] correspondences.\n",
      "Frame 8 had [87, 340, 151] correspondences.\n",
      "Frame 9 had [91, 323, 150] correspondences.\n",
      "Frame 10 had [88, 333, 137] correspondences.\n",
      "Frame 11 had [83, 343, 138] correspondences.\n",
      "Frame 12 had [86, 327, 138] correspondences.\n",
      "Frame 13 had [85, 336, 132] correspondences.\n",
      "Frame 14 had [86, 323, 131] correspondences.\n",
      "Frame 15 had [92, 317, 141] correspondences.\n",
      "Frame 16 had [96, 320, 135] correspondences.\n",
      "Frame 17 had [97, 322, 131] correspondences.\n",
      "Frame 18 had [96, 314, 136] correspondences.\n",
      "Frame 19 had [93, 319, 129] correspondences.\n",
      "Frame 20 had [97, 311, 141] correspondences.\n",
      "Frame 21 had [95, 327, 132] correspondences.\n",
      "Frame 22 had [99, 316, 147] correspondences.\n",
      "Frame 23 had [94, 307, 144] correspondences.\n",
      "Frame 24 had [90, 320, 138] correspondences.\n",
      "Frame 25 had [87, 332, 131] correspondences.\n",
      "Frame 26 had [88, 332, 137] correspondences.\n",
      "Frame 27 had [88, 332, 137] correspondences.\n",
      "Frame 28 had [96, 333, 155] correspondences.\n",
      "Frame 29 had [100, 316, 136] correspondences.\n",
      "Frame 30 had [97, 319, 137] correspondences.\n",
      "Frame 31 had [93, 340, 121] correspondences.\n",
      "Frame 32 had [101, 317, 119] correspondences.\n",
      "Frame 33 had [94, 328, 122] correspondences.\n",
      "Frame 34 had [91, 322, 136] correspondences.\n",
      "Frame 35 had [87, 322, 150] correspondences.\n",
      "Frame 36 had [100, 322, 134] correspondences.\n",
      "Frame 37 had [100, 317, 132] correspondences.\n",
      "Frame 38 had [102, 327, 127] correspondences.\n",
      "Frame 39 had [104, 309, 136] correspondences.\n",
      "Frame 40 had [102, 301, 136] correspondences.\n",
      "Frame 41 had [104, 315, 134] correspondences.\n",
      "Frame 42 had [93, 324, 137] correspondences.\n",
      "Frame 43 had [101, 309, 142] correspondences.\n",
      "Frame 44 had [97, 321, 138] correspondences.\n",
      "Frame 45 had [103, 320, 134] correspondences.\n",
      "Frame 46 had [100, 298, 127] correspondences.\n",
      "Frame 47 had [92, 334, 144] correspondences.\n",
      "Frame 48 had [103, 342, 119] correspondences.\n",
      "Frame 49 had [90, 320, 133] correspondences.\n",
      "Frame 50 had [100, 313, 134] correspondences.\n",
      "Frame 51 had [108, 305, 126] correspondences.\n",
      "Frame 52 had [96, 299, 146] correspondences.\n",
      "Frame 53 had [93, 325, 143] correspondences.\n",
      "Frame 54 had [89, 339, 134] correspondences.\n",
      "Frame 55 had [90, 328, 143] correspondences.\n",
      "Frame 56 had [100, 320, 142] correspondences.\n",
      "Frame 57 had [103, 314, 147] correspondences.\n",
      "Frame 58 had [92, 326, 148] correspondences.\n",
      "Frame 59 had [92, 340, 124] correspondences.\n",
      "Frame 60 had [98, 323, 141] correspondences.\n",
      "Frame 61 had [92, 323, 136] correspondences.\n",
      "Frame 62 had [99, 320, 132] correspondences.\n",
      "Frame 63 had [91, 324, 138] correspondences.\n",
      "Frame 64 had [96, 326, 128] correspondences.\n",
      "Frame 65 had [96, 343, 132] correspondences.\n",
      "Frame 66 had [92, 332, 130] correspondences.\n",
      "Frame 67 had [92, 334, 130] correspondences.\n",
      "Frame 68 had [104, 310, 135] correspondences.\n",
      "Frame 69 had [103, 307, 142] correspondences.\n",
      "Frame 70 had [102, 328, 126] correspondences.\n",
      "Frame 71 had [96, 328, 131] correspondences.\n",
      "Frame 72 had [97, 331, 138] correspondences.\n",
      "Frame 73 had [100, 329, 139] correspondences.\n",
      "Frame 74 had [93, 345, 128] correspondences.\n",
      "Frame 75 had [99, 335, 130] correspondences.\n",
      "Frame 76 had [106, 318, 144] correspondences.\n",
      "Frame 77 had [92, 328, 146] correspondences.\n",
      "Frame 78 had [89, 340, 139] correspondences.\n",
      "Frame 79 had [85, 334, 126] correspondences.\n",
      "Frame 80 had [91, 330, 133] correspondences.\n",
      "Frame 81 had [87, 321, 139] correspondences.\n",
      "Frame 82 had [84, 337, 135] correspondences.\n",
      "Frame 83 had [84, 339, 123] correspondences.\n",
      "Frame 84 had [84, 331, 131] correspondences.\n",
      "Frame 85 had [86, 321, 132] correspondences.\n",
      "Frame 86 had [87, 331, 125] correspondences.\n",
      "Frame 87 had [89, 322, 144] correspondences.\n",
      "Frame 88 had [81, 340, 131] correspondences.\n",
      "Frame 89 had [85, 346, 149] correspondences.\n",
      "Frame 90 had [96, 326, 138] correspondences.\n",
      "Frame 91 had [88, 326, 148] correspondences.\n",
      "Frame 92 had [88, 329, 127] correspondences.\n",
      "Frame 93 had [90, 323, 128] correspondences.\n",
      "Frame 94 had [93, 315, 128] correspondences.\n",
      "Frame 95 had [94, 328, 132] correspondences.\n",
      "Frame 96 had [95, 326, 132] correspondences.\n",
      "Frame 97 had [89, 327, 148] correspondences.\n",
      "Frame 98 had [90, 316, 129] correspondences.\n",
      "Frame 99 had [85, 340, 124] correspondences.\n",
      "Frame 100 had [84, 338, 136] correspondences.\n",
      "Frame 101 had [86, 325, 125] correspondences.\n",
      "Mask areas saved to res/mask_areas.csv\n"
     ]
    }
   ],
   "source": [
    "sequence = Sequence(ptv = ptv, exp=exp)\n",
    "sequence.do_sequence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1db0472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Renaming ../Runs_1003/Cam0_2025-03-10-13.32.35/%08d.tif to ../Runs_1003/Cam0_2025-03-10-13.32.35/ before C library tracker\n",
      " Renaming ../Runs_1003/Cam1_2025-03-10-13.33.28/%08d.tif to ../Runs_1003/Cam1_2025-03-10-13.33.28/ before C library tracker\n",
      " Renaming ../Runs_1003/Cam2_2025-03-10-13.34.40/%08d.tif to ../Runs_1003/Cam2_2025-03-10-13.34.40/ before C library tracker\n",
      " Renaming ../Runs_1003/Cam3_2025-03-10-13.36.08/%08d.tif to ../Runs_1003/Cam3_2025-03-10-13.36.08/ before C library tracker\n",
      "step: 1, curr: 566, next: 580, links: 243, lost: 323, add: 7\n",
      "time lapsed 328.945898 sec\n",
      "step: 2, curr: 580, next: 592, links: 293, lost: 287, add: 10\n",
      "step: 3, curr: 592, next: 585, links: 293, lost: 299, add: 7\n",
      "step: 4, curr: 585, next: 578, links: 295, lost: 290, add: 6\n",
      "step: 5, curr: 578, next: 581, links: 294, lost: 284, add: 12\n",
      "step: 6, curr: 581, next: 582, links: 285, lost: 296, add: 8\n",
      "step: 7, curr: 582, next: 586, links: 279, lost: 303, add: 6\n",
      "step: 8, curr: 586, next: 571, links: 264, lost: 322, add: 7\n",
      "step: 9, curr: 571, next: 566, links: 279, lost: 292, add: 9\n",
      "step: 10, curr: 566, next: 571, links: 290, lost: 276, add: 6\n",
      "step: 11, curr: 571, next: 558, links: 294, lost: 277, add: 12\n",
      "step: 12, curr: 558, next: 565, links: 290, lost: 268, add: 15\n",
      "step: 13, curr: 565, next: 556, links: 294, lost: 271, add: 11\n",
      "step: 14, curr: 556, next: 561, links: 294, lost: 262, add: 13\n",
      "step: 15, curr: 561, next: 564, links: 286, lost: 275, add: 8\n",
      "step: 16, curr: 564, next: 558, links: 304, lost: 260, add: 12\n",
      "step: 17, curr: 558, next: 558, links: 283, lost: 275, add: 11\n",
      "step: 18, curr: 558, next: 551, links: 296, lost: 262, add: 11\n",
      "step: 19, curr: 551, next: 559, links: 294, lost: 257, add: 7\n",
      "step: 20, curr: 559, next: 562, links: 279, lost: 280, add: 7\n",
      "step: 21, curr: 562, next: 568, links: 290, lost: 272, add: 9\n",
      "step: 22, curr: 568, next: 555, links: 291, lost: 277, add: 6\n",
      "step: 23, curr: 555, next: 554, links: 297, lost: 258, add: 13\n",
      "step: 24, curr: 554, next: 563, links: 315, lost: 239, add: 8\n",
      "step: 25, curr: 563, next: 565, links: 288, lost: 275, add: 9\n",
      "step: 26, curr: 565, next: 565, links: 278, lost: 287, add: 5\n",
      "step: 27, curr: 565, next: 589, links: 288, lost: 277, add: 6\n",
      "step: 28, curr: 589, next: 558, links: 295, lost: 294, add: 8\n",
      "step: 29, curr: 558, next: 561, links: 306, lost: 252, add: 9\n",
      "step: 30, curr: 561, next: 564, links: 302, lost: 259, add: 14\n",
      "step: 31, curr: 564, next: 552, links: 295, lost: 269, add: 14\n",
      "step: 32, curr: 552, next: 559, links: 277, lost: 275, add: 11\n",
      "step: 33, curr: 559, next: 557, links: 268, lost: 291, add: 5\n",
      "step: 34, curr: 557, next: 564, links: 277, lost: 280, add: 6\n",
      "step: 35, curr: 564, next: 564, links: 276, lost: 288, add: 8\n",
      "step: 36, curr: 564, next: 557, links: 277, lost: 287, add: 8\n",
      "step: 37, curr: 557, next: 562, links: 294, lost: 263, add: 10\n",
      "step: 38, curr: 562, next: 559, links: 299, lost: 263, add: 6\n",
      "step: 39, curr: 559, next: 546, links: 266, lost: 293, add: 14\n",
      "step: 40, curr: 546, next: 566, links: 278, lost: 268, add: 11\n",
      "step: 41, curr: 566, next: 565, links: 277, lost: 289, add: 6\n",
      "step: 42, curr: 565, next: 558, links: 288, lost: 277, add: 9\n",
      "step: 43, curr: 558, next: 566, links: 262, lost: 296, add: 7\n",
      "step: 44, curr: 566, next: 564, links: 273, lost: 293, add: 10\n",
      "step: 45, curr: 564, next: 534, links: 278, lost: 286, add: 6\n",
      "step: 46, curr: 534, next: 577, links: 255, lost: 279, add: 8\n",
      "step: 47, curr: 577, next: 572, links: 294, lost: 283, add: 12\n",
      "step: 48, curr: 572, next: 556, links: 284, lost: 288, add: 7\n",
      "step: 49, curr: 556, next: 555, links: 272, lost: 284, add: 13\n",
      "step: 50, curr: 555, next: 552, links: 295, lost: 260, add: 9\n",
      "step: 51, curr: 552, next: 547, links: 283, lost: 269, add: 6\n",
      "step: 52, curr: 547, next: 569, links: 281, lost: 266, add: 8\n",
      "step: 53, curr: 569, next: 570, links: 293, lost: 276, add: 7\n",
      "step: 54, curr: 570, next: 568, links: 306, lost: 264, add: 12\n",
      "step: 55, curr: 568, next: 573, links: 308, lost: 260, add: 14\n",
      "step: 56, curr: 573, next: 578, links: 318, lost: 255, add: 10\n",
      "step: 57, curr: 578, next: 575, links: 299, lost: 279, add: 10\n",
      "step: 58, curr: 575, next: 566, links: 284, lost: 291, add: 8\n",
      "step: 59, curr: 566, next: 572, links: 288, lost: 278, add: 9\n",
      "step: 60, curr: 572, next: 560, links: 287, lost: 285, add: 7\n",
      "step: 61, curr: 560, next: 557, links: 286, lost: 274, add: 10\n",
      "step: 62, curr: 557, next: 562, links: 287, lost: 270, add: 11\n",
      "step: 63, curr: 562, next: 563, links: 282, lost: 280, add: 9\n",
      "step: 64, curr: 563, next: 578, links: 290, lost: 273, add: 11\n",
      "step: 65, curr: 578, next: 565, links: 302, lost: 276, add: 12\n",
      "step: 66, curr: 565, next: 568, links: 298, lost: 267, add: 9\n",
      "step: 67, curr: 568, next: 560, links: 304, lost: 264, add: 10\n",
      "step: 68, curr: 560, next: 561, links: 307, lost: 253, add: 7\n",
      "step: 69, curr: 561, next: 562, links: 270, lost: 291, add: 8\n",
      "step: 70, curr: 562, next: 565, links: 269, lost: 293, add: 12\n",
      "step: 71, curr: 565, next: 577, links: 291, lost: 274, add: 14\n",
      "step: 72, curr: 577, next: 582, links: 292, lost: 285, add: 12\n",
      "step: 73, curr: 582, next: 579, links: 296, lost: 286, add: 10\n",
      "step: 74, curr: 579, next: 574, links: 296, lost: 283, add: 9\n",
      "step: 75, curr: 574, next: 577, links: 300, lost: 274, add: 10\n",
      "step: 76, curr: 577, next: 576, links: 298, lost: 279, add: 5\n",
      "step: 77, curr: 576, next: 571, links: 276, lost: 300, add: 10\n",
      "step: 78, curr: 571, next: 555, links: 298, lost: 273, add: 7\n",
      "step: 79, curr: 555, next: 562, links: 297, lost: 258, add: 4\n",
      "step: 80, curr: 562, next: 550, links: 314, lost: 248, add: 6\n",
      "step: 81, curr: 550, next: 562, links: 304, lost: 246, add: 14\n",
      "step: 82, curr: 562, next: 562, links: 304, lost: 258, add: 14\n",
      "step: 83, curr: 562, next: 558, links: 295, lost: 267, add: 3\n",
      "step: 84, curr: 558, next: 542, links: 295, lost: 263, add: 8\n",
      "step: 85, curr: 542, next: 552, links: 304, lost: 238, add: 14\n",
      "step: 86, curr: 552, next: 568, links: 279, lost: 273, add: 8\n",
      "step: 87, curr: 568, next: 562, links: 297, lost: 271, add: 7\n",
      "step: 88, curr: 562, next: 586, links: 305, lost: 257, add: 10\n",
      "step: 89, curr: 586, next: 570, links: 280, lost: 306, add: 7\n",
      "step: 90, curr: 570, next: 569, links: 287, lost: 283, add: 10\n",
      "step: 91, curr: 569, next: 553, links: 281, lost: 288, add: 9\n",
      "step: 92, curr: 553, next: 550, links: 285, lost: 268, add: 7\n",
      "step: 93, curr: 550, next: 544, links: 288, lost: 262, add: 8\n",
      "step: 94, curr: 544, next: 561, links: 279, lost: 265, add: 5\n",
      "step: 95, curr: 561, next: 558, links: 292, lost: 269, add: 13\n",
      "step: 96, curr: 558, next: 577, links: 302, lost: 256, add: 13\n",
      "step: 97, curr: 577, next: 549, links: 294, lost: 283, add: 12\n",
      "step: 98, curr: 549, next: 561, links: 289, lost: 260, add: 9\n",
      "step: 99, curr: 561, next: 568, links: 258, lost: 303, add: 10\n",
      "step: 100, curr: 568, next: 546, links: 251, lost: 317, add: 6\n",
      "Average over sequence, particles: 564.5, links: 288.3, lost: 276.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tracker = py_trackcorr_init(exp)\n",
    "tracker.full_forward()\n",
    "\n",
    "end = time.time()\n",
    "print(\"time lapsed %f sec\" % (end - start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b4bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_mask_areas(csv_file='res/mask_areas.csv'):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), height_ratios=[2, 1])\n",
    "    \n",
    "    # Plot 1: Area over time\n",
    "    for cam in sorted(df['camera'].unique()):\n",
    "        cam_data = df[df['camera'] == cam]\n",
    "        ax1.plot(cam_data['frame'], cam_data['area'], \n",
    "                label=f'Camera {cam}', \n",
    "                marker='o', \n",
    "                markersize=4, \n",
    "                alpha=0.7)\n",
    "    \n",
    "    ax1.set_xlabel('Frame Number')\n",
    "    ax1.set_ylabel('Mask Area (pixels)')\n",
    "    ax1.set_title('Mask Areas Over Time by Camera')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot 2: Box plot of areas by camera\n",
    "    sns.boxplot(data=df, x='camera', y='area', ax=ax2)\n",
    "    ax2.set_title('Distribution of Mask Areas by Camera')\n",
    "    ax2.set_xlabel('Camera')\n",
    "    ax2.set_ylabel('Area (pixels)')\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"\\nMask Area Statistics:\")\n",
    "    print(\"-\" * 40)\n",
    "    stats = df.groupby('camera')['area'].agg([\n",
    "        ('mean', 'mean'),\n",
    "        ('std', 'std'),\n",
    "        ('min', 'min'),\n",
    "        ('max', 'max')\n",
    "    ]).round(2)\n",
    "    print(stats)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig('res/mask_areas_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948ebde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mask Area Statistics:\n",
      "----------------------------------------\n",
      "                mean        std        min        max\n",
      "camera                                               \n",
      "0       1.937634e+08  434109.37  192819778  194472577\n",
      "1       1.717797e+08  955954.05  169572324  172860594\n",
      "2       1.592121e+08  887826.20  157253801  160304740\n",
      "3       1.475163e+08  799199.88  145694511  148504378\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# analyze_mask_areas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c432b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_normalized_areas(csv_file='res/mask_areas.csv'):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Create simple plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot one line per camera, normalized by first value\n",
    "    for cam in sorted(df['camera'].unique()):\n",
    "        cam_data = df[df['camera'] == cam]\n",
    "        # Normalize by the first value\n",
    "        normalized_area = cam_data['area'] / cam_data['area'].iloc[0]\n",
    "        plt.plot(cam_data['frame'], normalized_area, label=f'Camera {cam}')\n",
    "    \n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Normalized Area')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('res/normalized_areas.png')\n",
    "    plt.show()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "plot_normalized_areas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyptv-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
